Here is a draft for `Gemini.md`. This document will be Gemini's primary guide, mirroring `CLAUDE.md` in purpose but tailored to its specific responsibilities in building out the Google Cloud AI backend orchestrator.

---

# Gemini.md for VocaHire Coach (Google Cloud Pivot)

**Welcome to the VocaHire Coach Team, Gemini! This file is your primary guide for developing the Google Cloud-based AI backend services. Your collaboration with Claude, our other AI Developer, is crucial for success.**

**Your Core Mission:** Implement the backend AI Orchestration Service for VocaHire, leveraging Google Cloud AI services (Speech-to-Text, Text-to-Speech, Vertex AI Gemini/PaLM) and integrating seamlessly with the client-side components being managed by Claude.

## ü§ù COLLABORATIVE DEVELOPMENT NOTICE (As of May 25, 2025)

You are joining a collaborative development effort with Claude (Anthropic).
**Please thoroughly review the "ü§ù COLLABORATIVE DEVELOPMENT NOTICE" and "üîÑ Collaboration Best Practices" sections in the main `CLAUDE.md` file (in the project root).** These are our shared ground rules and are critical for effective teamwork.

**Key Highlights for Your Workflow:**
1.  **ALWAYS fetch latest changes** before starting any new task: `git pull origin main --rebase`
2.  **ALWAYS commit and push changes** after completing a logical unit of work.
3.  **Use descriptive, Conventional Commit messages**: `type(scope): [clear description] - by Gemini - $(date +'%Y-%m-%d')`
4.  **Document major decisions and API choices** in commit messages or code comments.
5.  **Leave clear `// TODO: [Claude/Gemini] - [description]` comments** for handoffs.
6.  **Prioritize tasks marked `[PIVOT-CRITICAL]`**.

## üìÖ Project Status & Your Role (As of May 26, 2025)

### Strategic Pivot: Google Cloud & Cloud Run
VocaHire is pivoting its core AI services from OpenAI to Google Cloud and its deployment from Vercel to Dockerized Cloud Run. You are leading the development of the new backend AI orchestration layer.

### Claude's Recent Progress (Handover Information):
Claude has successfully refactored the client-side components (`InterviewPageClient.tsx`, `InterviewRoom.tsx`, `hooks/useRealtimeInterviewSession.ts`) to:
1.  Remove all OpenAI-specific logic.
2.  Prepare for integration with a new backend orchestrator service (which you will build).
3.  Define the **API contract** for this orchestrator in `/docs/orchestrator-api-spec.md` (Version 1.1). **This document is your primary specification for the service you need to build.**
4.  The client now expects this orchestrator to be available at an environment variable `NEXT_PUBLIC_ORCHESTRATOR_URL` and to handle WebSocket connections at `/ws/{sessionId}` for signaling and data messages, with WebRTC for audio streaming.
5.  Claude has also set up the initial Dockerization foundation for the Next.js application.

### Your Initial Focus, Gemini:
1.  **Thoroughly review `/docs/orchestrator-api-spec.md` (Version 1.1).** This defines the endpoints, WebSocket messages, and WebRTC signaling flow your service must implement.
2.  **Implement the AI Orchestration Service** as new API routes within the existing Next.js application structure (e.g., under `/app/api/google-realtime-orchestrator/`). This service will be part of the Docker container Claude has set up.
3.  **Create utility functions in `/lib/google-cloud-utils.ts`** for interacting with Google Cloud Speech-to-Text, Text-to-Speech, and Vertex AI (Gemini models).
4.  **Integrate these Google Cloud services** into your orchestrator to fulfill the API contract.
5.  **Work closely with Claude's client-side implementation** for end-to-end testing.

## üöÄ ACTIVE DEVELOPMENT: Google Cloud MVP Configuration (Your Responsibility)

**[PIVOT-CRITICAL] You are responsible for building and refining the backend components of this Google Cloud architecture.**

### Target Google Cloud AI Components & Your Role:

1.  **Speech-to-Text (STT):** Google Cloud Speech-to-Text API (streaming, USM).
    *   **Your Task:** Implement streaming STT from audio received via WebRTC from the client. Handle interim and final results.
    *   **Your Task:** Implement custom vocabulary/model adaptation features (discuss with Kyle/CPO for initial vocabulary).
    *   **Your Task:** Utilize `enable_voice_activity_events` for server-side VAD.

2.  **Text-to-Speech (TTS):** Google Cloud Text-to-Speech API (WaveNet/Neural2, Chirp HD).
    *   **Your Task:** Implement TTS from text generated by the LLM.
    *   **Your Task:** Develop utilities for generating effective SSML to ensure natural, expressive AI speech.
    *   **Your Task:** Ensure low-latency streaming of TTS audio back to the client via WebRTC.

3.  **Natural Language Understanding (NLU) & Conversational AI:** Google Vertex AI (Gemini models preferred).
    *   **Your Task:** Implement logic to call Gemini with conversation history and STT transcripts.
    *   **Your Task:** Manage conversation context windows effectively.
    *   **Your Task:** Work with Kyle/CPO on prompt engineering for the interview coach persona and dynamic question generation.
    *   **Your Task:** Integrate Google Cloud Natural Language API for supplementary analysis if required by the product spec.

4.  **Backend Orchestration Service (Your Core Build):**
    *   **Location:** Start by creating routes under `/app/api/google-realtime-orchestrator/`.
    *   **Functionality:**
        *   Implement all endpoints defined in `/docs/orchestrator-api-spec.md`.
        *   Handle WebSocket connections at `/ws/{sessionId}` for signaling, transcript delivery, and control messages as per the spec.
        *   Manage the server-side WebRTC peer connection: receive client's offer (via WebSocket), generate an answer, and handle ICE candidates (via WebSocket).
        *   Orchestrate the STT ‚Üí LLM ‚Üí TTS pipeline for each turn.
        *   Implement robust turn-taking logic using VAD events and potentially client hints.
        *   Manage session state (e.g., current question, context).

5.  **Utilities (`/lib/google-cloud-utils.ts`):**
    *   **Your Task:** Create functions for:
        *   Authenticating with Google Cloud (leveraging service accounts for Cloud Run).
        *   Initializing and using Google Cloud API clients (STT, TTS, Vertex AI).
        *   Handling streaming data to/from these services.
        *   Error mapping and handling for Google Cloud API responses.

### Files for Your Implementation (Focus Areas):
*   **New Backend Service**: `/app/api/google-realtime-orchestrator/` (and its sub-routes/handlers). **[YOUR PRIMARY DOMAIN]**
*   **New Utilities**: `/lib/google-cloud-utils.ts`. **[YOUR PRIMARY DOMAIN]**
*   `Dockerfile`: Review and enhance, particularly for any build steps or runtime dependencies your orchestrator service might need.
*   `/docs/orchestrator-api-spec.md`: Your guiding specification. Propose changes/clarifications if needed.

## Guidance for AI Developer Gemini (VocaHire - Google Cloud Pivot)

### Understanding the Vocahire Codebase:
*   Familiarize yourself with the existing Next.js structure, Prisma (`lib/prisma.ts`), Clerk auth (`middleware.ts`), and payment logic (`lib/payment-config.ts`), as your service will integrate within this application.
*   Pay close attention to `/hooks/useRealtimeInterviewSession.ts` (as refactored by Claude) to understand the client-side expectations for your orchestrator.
*   Review `CLAUDE.md` for broader project context, but this `Gemini.md` is your specific guide.

### Making Changes:
*   **Code Style:** Adhere to existing TypeScript, ESLint, Prettier standards.
*   **Testing:**
    *   **Unit Tests:** For utilities in `/lib/google-cloud-utils.ts` and individual logic units in your orchestrator.
    *   **Integration Tests:** Plan for testing the STT-LLM-TTS pipeline. You might need to mock Google Cloud API responses for some tests.
    *   **End-to-End Tests:** Collaborate with Claude to test the full client-orchestrator-Google Cloud flow.
*   **Commits & Error Handling:** Follow project standards (Conventional Commits, Sentry).

### Git & GitHub Workflow:
*   Follow the shared protocol in `CLAUDE.md`. Create feature branches for significant parts of the orchestrator (e.g., `feature/gcp-stt-integration`, `feature/orchestrator-webrtc-signaling`).

### Debugging and Verification:
*   Use the project's diagnostic endpoints. You may need to add new ones specific to your orchestrator's health and its connections to Google Cloud services.
*   Leverage Google Cloud Console for monitoring STT, TTS, and Vertex AI API usage and errors.
*   Local testing via `docker-compose` (once your service is integrated) will be key.

### Dockerization & Cloud Run:
*   Your orchestrator logic will run within the Next.js application's Docker container deployed on Cloud Run.
*   Ensure your code correctly handles Google Cloud authentication in the Cloud Run environment (typically via the attached service account, so `GOOGLE_APPLICATION_CREDENTIALS` env var might not be needed *in* Cloud Run if IAM roles are set correctly).
*   Be mindful of Cloud Run's stateless nature for any session management within your orchestrator (though primary session state might live in Redis or be passed from client).
*   Optimize for quick cold starts if possible, though some AI client initializations can be slow.

### Key Technical Challenges for Your Implementation:
1.  **Low-Latency Streaming:** Ensuring audio and text data streams efficiently between the client, your orchestrator, and multiple Google Cloud APIs.
2.  **Robust WebRTC Signaling:** Implementing the server-side WebRTC signaling (offer/answer, ICE candidates) via WebSockets as per the `/docs/orchestrator-api-spec.md`.
3.  **Natural Turn-Taking:** Developing sophisticated logic to determine when the user has finished speaking (using Google STT VAD) and when the AI should respond, including handling barge-ins.
4.  **Error Propagation:** Gracefully handling errors from any of the Google Cloud services and propagating meaningful error states back to the client.
5.  **Context Management for LLM:** Efficiently passing and managing conversation history to Google Vertex AI (Gemini/PaLM) within its token limits.
6.  **SSML Generation:** Creating dynamic and effective SSML for Google TTS to make the AI voice engaging.

---
*(The rest of the `CLAUDE.MD` content regarding Project Overview, Existing Architecture (Core Tech updated), Dev Commands (add Docker & GCP specific ones), Important Files (updated), DB Management, Migrations, Performance Opts, Env Vars (updated for GCP), Webhooks, Auth, Deployment (now Cloud Run), Dependencies (updated for GCP), Payments, Production Readiness standards, Error Monitoring, Build System (updated for Docker), Interview Data Persistence, Credits System, remain largely the same and are good context for you. Refer to `CLAUDE.md` for these sections.)*

---

**Gemini, your role is pivotal in making this Google Cloud transition a success. Focus on building a reliable, performant, and scalable AI Orchestration Service. Communicate closely with Claude (via code comments, commit messages, and updates to the API spec if needed) to ensure smooth integration.**

Welcome aboard! We're excited to have your expertise in building with Google Cloud.